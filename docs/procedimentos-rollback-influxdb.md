# Procedimentos de Rollback e Recupera√ß√£o de Desastre - InfluxDB

## Vis√£o Geral

Este documento fornece procedimentos abrangentes de rollback e planos de recupera√ß√£o de desastre espec√≠ficos para a migra√ß√£o do InfluxDB. Cobre cen√°rios para rollback para Timestream, recupera√ß√£o de falhas do InfluxDB e manuten√ß√£o da integridade dos dados durante emerg√™ncias.

## √çndice

1. [Rollback de Emerg√™ncia para Timestream](#rollback-de-emerg√™ncia-para-timestream)
2. [Recupera√ß√£o de Inst√¢ncia InfluxDB](#recupera√ß√£o-de-inst√¢ncia-influxdb)
3. [Recupera√ß√£o de Corrup√ß√£o de Dados](#recupera√ß√£o-de-corrup√ß√£o-de-dados)
4. [Rollback de Fun√ß√µes Lambda](#rollback-de-fun√ß√µes-lambda)
5. [Rollback de Performance de Consultas](#rollback-de-performance-de-consultas)
6. [Cen√°rios de Recupera√ß√£o de Desastre](#cen√°rios-de-recupera√ß√£o-de-desastre)
7. [Teste de Procedimentos de Rollback](#teste-de-procedimentos-de-rollback)

## Rollback de Emerg√™ncia para Timestream

### Quando Executar Rollback de Emerg√™ncia

Execute rollback de emerg√™ncia para Timestream quando:
- Inst√¢ncia InfluxDB est√° completamente indispon√≠vel por >30 minutos
- Corrup√ß√£o de dados √© detectada no InfluxDB
- Performance de consultas est√° degradada em >300% comparado √† baseline
- Opera√ß√µes cr√≠ticas de neg√≥cio est√£o impactadas

### Lista de Verifica√ß√£o Pr√©-Rollback

```bash
#!/bin/bash
# Script de avalia√ß√£o pr√©-rollback

echo "=== Avalia√ß√£o Pr√©-Rollback ==="

# 1. Avaliar status do InfluxDB
echo "1. Status do InfluxDB:"
aws timestreaminfluxdb describe-db-instance \
  --identifier ons-influxdb-prod \
  --query 'DbInstance.DbInstanceStatus' --output text

# 2. Verificar atualiza√ß√£o de dados no Timestream (backup)
echo "2. Status do Backup Timestream:"
aws timestream-query query \
  --query-string "SELECT COUNT(*), MAX(time) FROM \"ons_energy_data_backup\".\"generation_data\" WHERE time > ago(1h)" \
  --query 'Rows[*].Data[*].ScalarValue' --output text

# 3. Verificar vers√µes das fun√ß√µes Lambda
echo "3. Vers√µes das Fun√ß√µes Lambda:"
for func in lambda_router structured_data_processor rag_query_processor; do
    current_version=$(aws lambda get-function --function-name $func --query 'Configuration.Version' --output text)
    echo "$func: Atual=$current_version"
done

# 4. Verificar sa√∫de da API
echo "4. Verifica√ß√£o de Sa√∫de da API:"
curl -s -o /dev/null -w "%{http_code}" "https://api.ons-platform.com/health"

# 5. Estimar tempo de rollback
echo "5. Tempo Estimado de Rollback: 15-30 minutos"
echo "6. Impacto no Neg√≥cio: Consultas da API ficar√£o indispon√≠veis durante o rollback"

read -p "Prosseguir com rollback? (sim/nao): " confirm
if [ "$confirm" != "sim" ]; then
    echo "Rollback cancelado"
    exit 1
fi
```

### Passo 1: Desvio Imediato de Tr√°fego

```bash
#!/bin/bash
# Desvio imediato de tr√°fego para modo de manuten√ß√£o

echo "Passo 1: Desviando tr√°fego para modo de manuten√ß√£o..."

# Habilitar flag de modo de manuten√ß√£o
python scripts/deploy.py --action update-flag \
  --application-id $(terraform output -raw appconfig_application_id) \
  --environment-id $(terraform output -raw appconfig_production_environment_id) \
  --profile-id $(terraform output -raw appconfig_feature_flags_profile_id) \
  --flag-name enable_maintenance_mode \
  --enabled true

# Reduzir throttling do API Gateway ao m√≠nimo
api_id=$(aws apigateway get-rest-apis --query 'items[?name==`ons-data-platform-api`].id' --output text)
aws apigateway update-stage \
  --rest-api-id $api_id \
  --stage-name prod \
  --patch-ops op=replace,path=/throttle/rateLimit,value=1

echo "Tr√°fego desviado para modo de manuten√ß√£o"
```

### Passo 2: Rollback das Fun√ß√µes Lambda

```bash
#!/bin/bash
# Rollback das fun√ß√µes Lambda para vers√µes Timestream

echo "Passo 2: Fazendo rollback das fun√ß√µes Lambda..."

# Mapeamento de rollback de fun√ß√µes
declare -A ROLLBACK_VERSIONS=(
    ["influxdb_loader"]="timestream_loader:5"
    ["timeseries_query_processor"]="timestream_query_processor:3"
    ["rag_query_processor"]="rag_query_processor:4"
)

for current_func in "${!ROLLBACK_VERSIONS[@]}"; do
    IFS=':' read -r target_func target_version <<< "${ROLLBACK_VERSIONS[$current_func]}"
    
    echo "Fazendo rollback de $current_func para $target_func vers√£o $target_version"
    
    # Atualizar c√≥digo da fun√ß√£o para vers√£o Timestream
    aws lambda update-function-code \
      --function-name $current_func \
      --s3-bucket ons-lambda-deployments \
      --s3-key "rollback-versions/${target_func}-v${target_version}.zip"
    
    # Atualizar vari√°veis de ambiente para Timestream
    aws lambda update-function-configuration \
      --function-name $current_func \
      --environment Variables="{
        TIMESTREAM_DATABASE_NAME=ons_energy_data,
        GENERATION_TABLE_NAME=generation_data,
        CONSUMPTION_TABLE_NAME=consumption_data,
        TRANSMISSION_TABLE_NAME=transmission_data,
        USE_INFLUXDB=false
      }"
    
    # Aguardar conclus√£o da atualiza√ß√£o
    aws lambda wait function-updated --function-name $current_func
    
    echo "$current_func rollback realizado com sucesso"
done
```

### Passo 3: Restaurar Pipeline de Dados Timestream

```bash
#!/bin/bash
# Restaurar pipeline de dados Timestream

echo "Passo 3: Restaurando pipeline de dados Timestream..."

# Reabilitar opera√ß√µes de escrita Timestream
aws events put-rule \
  --name ons-data-platform-timestream-processing \
  --event-pattern '{
    "source": ["aws.s3"],
    "detail-type": ["Object Created"],
    "detail": {
      "bucket": {"name": ["ons-data-platform-processed-prod"]}
    }
  }' \
  --state ENABLED

# Atualizar Step Functions para usar loader Timestream
aws stepfunctions update-state-machine \
  --state-machine-arn $(terraform output -raw step_function_arn) \
  --definition file://rollback-configs/timestream-state-machine.json

# Verificar acessibilidade do banco Timestream
aws timestream-query query \
  --query-string "SELECT COUNT(*) FROM \"ons_energy_data\".\"generation_data\" WHERE time > ago(5m)" \
  --query 'Rows[0].Data[0].ScalarValue' --output text

echo "Pipeline de dados Timestream restaurado"
```

### Passo 4: Atualizar Configura√ß√£o da API

```bash
#!/bin/bash
# Atualizar configura√ß√£o da API para Timestream

echo "Passo 4: Atualizando configura√ß√£o da API..."

# Atualizar feature flags para desabilitar recursos InfluxDB
python scripts/deploy.py --action update-flag \
  --application-id $(terraform output -raw appconfig_application_id) \
  --environment-id $(terraform output -raw appconfig_production_environment_id) \
  --profile-id $(terraform output -raw appconfig_feature_flags_profile_id) \
  --flag-name use_influxdb \
  --enabled false

python scripts/deploy.py --action update-flag \
  --application-id $(terraform output -raw appconfig_application_id) \
  --environment-id $(terraform output -raw appconfig_production_environment_id) \
  --profile-id $(terraform output -raw appconfig_feature_flags_profile_id) \
  --flag-name enable_flux_queries \
  --enabled false

# Atualizar API Gateway para usar endpoints Timestream
aws apigateway update-integration \
  --rest-api-id $api_id \
  --resource-id $(aws apigateway get-resources --rest-api-id $api_id --query 'items[?pathPart==`query`].id' --output text) \
  --http-method POST \
  --patch-ops op=replace,path=/uri,value=arn:aws:apigateway:us-east-1:lambda:path/2015-03-31/functions/arn:aws:lambda:us-east-1:123456789012:function:timestream_query_processor/invocations

echo "Configura√ß√£o da API atualizada para Timestream"
```

### Passo 5: Valida√ß√£o e Restaura√ß√£o de Tr√°fego

```bash
#!/bin/bash
# Validar rollback e restaurar tr√°fego

echo "Passo 5: Validando rollback..."

# Testar conectividade Timestream
test_query_result=$(aws timestream-query query \
  --query-string "SELECT COUNT(*) FROM \"ons_energy_data\".\"generation_data\" WHERE time > ago(1h)" \
  --query 'Rows[0].Data[0].ScalarValue' --output text)

if [ "$test_query_result" -gt 0 ]; then
    echo "Conectividade Timestream verificada: $test_query_result registros encontrados"
else
    echo "ERRO: Teste de conectividade Timestream falhou"
    exit 1
fi

# Testar endpoints da API
api_response=$(curl -s -X POST "https://api.ons-platform.com/query" \
  -H "Content-Type: application/json" \
  -H "x-api-key: $API_KEY" \
  -d '{"question": "Qual √© a gera√ß√£o de energia atual?"}' \
  -w "%{http_code}")

if [[ "$api_response" == *"200" ]]; then
    echo "Teste de endpoint da API bem-sucedido"
else
    echo "ERRO: Teste de endpoint da API falhou"
    exit 1
fi

# Restaurar tr√°fego gradualmente
echo "Restaurando tr√°fego da API..."

# Aumentar limites de taxa gradualmente
for rate in 10 50 100 500; do
    aws apigateway update-stage \
      --rest-api-id $api_id \
      --stage-name prod \
      --patch-ops op=replace,path=/throttle/rateLimit,value=$rate
    
    echo "Limite de taxa aumentado para $rate requisi√ß√µes/segundo"
    sleep 30
    
    # Verificar taxas de erro
    error_count=$(aws logs filter-log-events \
      --log-group-name "API-Gateway-Execution-Logs_${api_id}/prod" \
      --start-time $(date -d '1 minute ago' +%s)000 \
      --filter-pattern "ERROR" \
      --query 'length(events)' --output text)
    
    if [ "$error_count" -gt 5 ]; then
        echo "Alta taxa de erro detectada, parando aumento de tr√°fego"
        break
    fi
done

# Desabilitar modo de manuten√ß√£o
python scripts/deploy.py --action update-flag \
  --application-id $(terraform output -raw appconfig_application_id) \
  --environment-id $(terraform output -raw appconfig_production_environment_id) \
  --profile-id $(terraform output -raw appconfig_feature_flags_profile_id) \
  --flag-name enable_maintenance_mode \
  --enabled false

echo "Rollback para Timestream conclu√≠do com sucesso"
```

## Recupera√ß√£o de Inst√¢ncia InfluxDB

### Recupera√ß√£o de Falha de Inst√¢ncia

```bash
#!/bin/bash
# Recupera√ß√£o de falha de inst√¢ncia InfluxDB

recover_influxdb_instance() {
    local instance_id="ons-influxdb-prod"
    local backup_snapshot_id=$1
    
    echo "Iniciando recupera√ß√£o de inst√¢ncia InfluxDB..."
    
    # Verificar status atual da inst√¢ncia
    current_status=$(aws timestreaminfluxdb describe-db-instance \
      --identifier $instance_id \
      --query 'DbInstance.DbInstanceStatus' --output text 2>/dev/null || echo "not-found")
    
    if [ "$current_status" == "not-found" ] || [ "$current_status" == "failed" ]; then
        echo "Inst√¢ncia falhou ou est√° ausente, criando nova inst√¢ncia a partir do snapshot..."
        
        # Criar nova inst√¢ncia a partir do snapshot mais recente
        if [ -z "$backup_snapshot_id" ]; then
            backup_snapshot_id=$(aws timestreaminfluxdb describe-db-snapshots \
              --db-instance-identifier $instance_id \
              --query 'DbSnapshots[0].DbSnapshotIdentifier' --output text)
        fi
        
        aws timestreaminfluxdb restore-db-instance-from-db-snapshot \
          --db-instance-identifier "${instance_id}-recovery" \
          --db-snapshot-identifier $backup_snapshot_id \
          --db-instance-class db.influx.large \
          --publicly-accessible false \
          --storage-encrypted true
        
        # Aguardar inst√¢ncia ficar dispon√≠vel
        echo "Aguardando inst√¢ncia de recupera√ß√£o ficar dispon√≠vel..."
        aws timestreaminfluxdb wait db-instance-available \
          --db-instance-identifier "${instance_id}-recovery"
        
        # Atualizar fun√ß√µes Lambda para usar inst√¢ncia de recupera√ß√£o
        recovery_endpoint=$(aws timestreaminfluxdb describe-db-instance \
          --identifier "${instance_id}-recovery" \
          --query 'DbInstance.Endpoint' --output text)
        
        for func in influxdb_loader timeseries_query_processor rag_query_processor; do
            aws lambda update-function-configuration \
              --function-name $func \
              --environment Variables="{INFLUXDB_ENDPOINT=$recovery_endpoint}"
        done
        
        echo "Recupera√ß√£o de inst√¢ncia InfluxDB conclu√≠da"
        
    elif [ "$current_status" == "available" ]; then
        echo "Inst√¢ncia est√° dispon√≠vel, verificando conectividade..."
        
        # Testar conectividade
        python -c "
from src.shared_utils.influxdb_client import InfluxDBHandler
try:
    handler = InfluxDBHandler()
    health = handler.health_check()
    print(f'Verifica√ß√£o de sa√∫de InfluxDB: {health}')
except Exception as e:
    print(f'Conectividade InfluxDB falhou: {str(e)}')
    exit(1)
"
        
        echo "Inst√¢ncia InfluxDB est√° saud√°vel"
    else
        echo "Status da inst√¢ncia: $current_status - monitorando para recupera√ß√£o"
    fi
}

# Uso: recover_influxdb_instance [snapshot_id]
```

### Recupera√ß√£o de Sincroniza√ß√£o de Dados

```python
def recover_data_synchronization():
    """Recuperar sincroniza√ß√£o de dados entre S3 e InfluxDB"""
    import boto3
    from datetime import datetime, timedelta
    from src.shared_utils.influxdb_client import InfluxDBHandler
    
    s3_client = boto3.client('s3')
    influx_handler = InfluxDBHandler()
    
    # Encontrar lacunas de dados
    print("Analisando lacunas de dados...")
    
    # Obter timestamp mais recente no InfluxDB
    latest_query = '''
    from(bucket: "energy_data")
      |> range(start: -7d)
      |> last()
      |> keep(columns: ["_time"])
    '''
    
    try:
        latest_result = influx_handler.query_flux(latest_query)
        if latest_result:
            latest_influx_time = latest_result[0]['_time']
            print(f"Dados mais recentes no InfluxDB: {latest_influx_time}")
        else:
            latest_influx_time = datetime.utcnow() - timedelta(days=7)
            print("Nenhum dado recente encontrado no InfluxDB, iniciando de 7 dias atr√°s")
    except Exception as e:
        print(f"Erro ao consultar InfluxDB: {e}")
        latest_influx_time = datetime.utcnow() - timedelta(days=1)
    
    # Encontrar arquivos n√£o processados no S3
    bucket_name = 'ons-data-platform-processed-prod'
    prefix = 'dataset=generation/'
    
    response = s3_client.list_objects_v2(
        Bucket=bucket_name,
        Prefix=prefix,
        StartAfter=f"{prefix}year={latest_influx_time.year}/month={latest_influx_time.month:02d}/"
    )
    
    unprocessed_files = []
    for obj in response.get('Contents', []):
        if obj['LastModified'] > latest_influx_time:
            unprocessed_files.append(obj['Key'])
    
    print(f"Encontrados {len(unprocessed_files)} arquivos n√£o processados")
    
    # Reprocessar arquivos ausentes
    for file_key in unprocessed_files:
        try:
            print(f"Reprocessando {file_key}...")
            
            # Disparar fun√ß√£o Lambda para processar arquivo
            lambda_client = boto3.client('lambda')
            lambda_client.invoke(
                FunctionName='influxdb_loader',
                InvocationType='Event',
                Payload=json.dumps({
                    'Records': [{
                        's3': {
                            'bucket': {'name': bucket_name},
                            'object': {'key': file_key}
                        }
                    }]
                })
            )
            
        except Exception as e:
            print(f"Erro ao reprocessar {file_key}: {e}")
    
    print("Recupera√ß√£o de sincroniza√ß√£o de dados conclu√≠da")

# Executar recupera√ß√£o
recover_data_synchronization()
```

## Recupera√ß√£o de Corrup√ß√£o de Dados

### Detectar Corrup√ß√£o de Dados

```python
def detect_data_corruption():
    """Detectar potencial corrup√ß√£o de dados no InfluxDB"""
    from src.shared_utils.influxdb_client import InfluxDBHandler
    import pandas as pd
    
    handler = InfluxDBHandler()
    
    corruption_checks = []
    
    # Verifica√ß√£o 1: Timestamps duplicados
    duplicate_check = '''
    from(bucket: "energy_data")
      |> range(start: -24h)
      |> group(columns: ["_measurement", "region", "energy_source"])
      |> duplicate(column: "_time")
      |> count()
    '''
    
    try:
        duplicates = handler.query_flux(duplicate_check)
        duplicate_count = sum(record.get('_value', 0) for record in duplicates)
        corruption_checks.append({
            'check': 'timestamps_duplicados',
            'status': 'FALHA' if duplicate_count > 0 else 'PASSOU',
            'details': f'{duplicate_count} timestamps duplicados encontrados'
        })
    except Exception as e:
        corruption_checks.append({
            'check': 'timestamps_duplicados',
            'status': 'ERRO',
            'details': str(e)
        })
    
    # Verifica√ß√£o 2: Valores nulos em campos obrigat√≥rios
    null_check = '''
    from(bucket: "energy_data")
      |> range(start: -24h)
      |> filter(fn: (r) => not exists r._value or r._value == 0)
      |> count()
    '''
    
    try:
        nulls = handler.query_flux(null_check)
        null_count = sum(record.get('_value', 0) for record in nulls)
        corruption_checks.append({
            'check': 'valores_nulos',
            'status': 'FALHA' if null_count > 100 else 'PASSOU',  # Permitir alguns nulos
            'details': f'{null_count} valores nulos encontrados'
        })
    except Exception as e:
        corruption_checks.append({
            'check': 'valores_nulos',
            'status': 'ERRO',
            'details': str(e)
        })
    
    # Verifica√ß√£o 3: Consist√™ncia de dados com S3
    consistency_check = '''
    from(bucket: "energy_data")
      |> range(start: -1h)
      |> count()
    '''
    
    try:
        recent_count = handler.query_flux(consistency_check)
        influx_count = sum(record.get('_value', 0) for record in recent_count)
        
        # Comparar com contagem esperada dos logs de processamento S3
        # Esta √© uma verifica√ß√£o simplificada - na pr√°tica, voc√™ consultaria logs do CloudWatch
        expected_count = 1000  # Placeholder
        
        consistency_ratio = influx_count / expected_count if expected_count > 0 else 0
        corruption_checks.append({
            'check': 'consistencia_dados',
            'status': 'FALHA' if consistency_ratio < 0.9 else 'PASSOU',
            'details': f'InfluxDB: {influx_count}, Esperado: {expected_count}, Propor√ß√£o: {consistency_ratio:.2f}'
        })
    except Exception as e:
        corruption_checks.append({
            'check': 'consistencia_dados',
            'status': 'ERRO',
            'details': str(e)
        })
    
    # Reportar resultados
    print("Resultados da Verifica√ß√£o de Corrup√ß√£o de Dados:")
    print("=" * 50)
    
    failed_checks = 0
    for check in corruption_checks:
        status_symbol = "‚úì" if check['status'] == 'PASSOU' else "‚úó" if check['status'] == 'FALHA' else "?"
        print(f"{status_symbol} {check['check']}: {check['status']} - {check['details']}")
        
        if check['status'] == 'FALHA':
            failed_checks += 1
    
    if failed_checks > 0:
        print(f"\n‚ö†Ô∏è  {failed_checks} verifica√ß√µes de corrup√ß√£o falharam!")
        return False
    else:
        print("\n‚úÖ Todas as verifica√ß√µes de corrup√ß√£o passaram")
        return True

# Executar detec√ß√£o de corrup√ß√£o
is_data_healthy = detect_data_corruption()
```

### Restaurar de Backup Limpo

```bash
#!/bin/bash
# Restaurar InfluxDB de backup limpo

restore_from_clean_backup() {
    local backup_date=$1
    local backup_bucket="ons-data-platform-backups"
    
    if [ -z "$backup_date" ]; then
        echo "Uso: restore_from_clean_backup YYYYMMDD_HHMMSS"
        return 1
    fi
    
    echo "Restaurando InfluxDB do backup: $backup_date"
    
    # 1. Parar ingest√£o de dados
    echo "Parando ingest√£o de dados..."
    aws events disable-rule --name ons-data-platform-s3-processing-rule
    
    # 2. Criar nova inst√¢ncia InfluxDB
    echo "Criando nova inst√¢ncia InfluxDB..."
    aws timestreaminfluxdb create-db-instance \
      --db-instance-identifier "ons-influxdb-restore-${backup_date}" \
      --db-instance-class db.influx.large \
      --engine influxdb \
      --master-username admin \
      --master-user-password $(aws secretsmanager get-secret-value --secret-id ons-influxdb-password --query SecretString --output text) \
      --allocated-storage 100 \
      --storage-encrypted \
      --vpc-security-group-ids $(terraform output -raw influxdb_security_group_id) \
      --db-subnet-group-name $(terraform output -raw influxdb_subnet_group_name)
    
    # Aguardar inst√¢ncia ficar dispon√≠vel
    aws timestreaminfluxdb wait db-instance-available \
      --db-instance-identifier "ons-influxdb-restore-${backup_date}"
    
    # 3. Restaurar dados do backup S3
    echo "Restaurando dados do backup S3..."
    python -c "
import boto3
import json
from src.shared_utils.influxdb_client import InfluxDBHandler
from influxdb_client import Point
import os

# Atualizar ambiente para usar inst√¢ncia de restaura√ß√£o
restore_endpoint = '$(aws timestreaminfluxdb describe-db-instance --identifier ons-influxdb-restore-${backup_date} --query 'DbInstance.Endpoint' --output text)'
os.environ['INFLUXDB_ENDPOINT'] = restore_endpoint

s3_client = boto3.client('s3')
handler = InfluxDBHandler()

# Baixar dados de backup
backup_key = f'influxdb_backup_${backup_date}/data_export.json'
response = s3_client.get_object(Bucket='$backup_bucket', Key=backup_key)
backup_data = json.loads(response['Body'].read())

print(f'Restaurando {backup_data[\"data_count\"]} registros...')

# Converter e escrever dados
points = []
for record in backup_data['data']:
    point = Point(record.get('_measurement', 'restored_data'))
    
    # Adicionar tags e fields
    for key, value in record.items():
        if key.startswith('tag_'):
            point = point.tag(key[4:], str(value))
        elif key.startswith('field_'):
            point = point.field(key[6:], float(value))
        elif key == '_time':
            point = point.time(value)
    
    points.append(point)
    
    # Escrever em lotes
    if len(points) >= 1000:
        handler.write_points(points)
        points = []
        print('.', end='', flush=True)

# Escrever pontos restantes
if points:
    handler.write_points(points)

print(f'\nRestaura√ß√£o de dados conclu√≠da: {backup_data[\"data_count\"]} registros')
"
    
    # 4. Validar dados restaurados
    echo "Validando dados restaurados..."
    python scripts/validate_influxdb_performance.py --health-check-only
    
    # 5. Alternar para inst√¢ncia restaurada
    echo "Alternando para inst√¢ncia restaurada..."
    restore_endpoint=$(aws timestreaminfluxdb describe-db-instance \
      --identifier "ons-influxdb-restore-${backup_date}" \
      --query 'DbInstance.Endpoint' --output text)
    
    for func in influxdb_loader timeseries_query_processor rag_query_processor; do
        aws lambda update-function-configuration \
          --function-name $func \
          --environment Variables="{INFLUXDB_ENDPOINT=$restore_endpoint}"
    done
    
    # 6. Retomar ingest√£o de dados
    echo "Retomando ingest√£o de dados..."
    aws events enable-rule --name ons-data-platform-s3-processing-rule
    
    echo "Restaura√ß√£o de backup limpo conclu√≠da com sucesso"
}

# Uso: restore_from_clean_backup "20241201_120000"
```

## Teste de Procedimentos de Rollback

### Teste Automatizado de Rollback

```bash
#!/bin/bash
# Script de teste automatizado de procedimentos de rollback

test_rollback_procedures() {
    echo "=== Teste de Procedimentos de Rollback ==="
    
    # Configura√ß√£o do ambiente de teste
    export TEST_ENVIRONMENT="staging"
    export TEST_INFLUXDB_INSTANCE="ons-influxdb-staging"
    export TEST_API_ENDPOINT="https://staging-api.ons-platform.com"
    
    # Teste 1: Rollback de fun√ß√£o Lambda
    echo "Teste 1: Rollback de Fun√ß√£o Lambda"
    test_lambda_rollback
    
    # Teste 2: Rollback de configura√ß√£o
    echo "Teste 2: Rollback de Configura√ß√£o"
    test_configuration_rollback
    
    # Teste 3: Recupera√ß√£o de dados
    echo "Teste 3: Recupera√ß√£o de Dados"
    test_data_recovery
    
    # Teste 4: Valida√ß√£o end-to-end
    echo "Teste 4: Valida√ß√£o End-to-End"
    test_end_to_end_validation
    
    echo "=== Teste de Rollback Conclu√≠do ==="
}

test_lambda_rollback() {
    # Implantar vers√£o de teste
    aws lambda update-function-code \
      --function-name "${TEST_ENVIRONMENT}-influxdb-loader" \
      --zip-file fileb://test-artifacts/test-function.zip
    
    # Testar rollback
    aws lambda update-function-code \
      --function-name "${TEST_ENVIRONMENT}-influxdb-loader" \
      --zip-file fileb://rollback-versions/timestream_loader-v5.zip
    
    # Validar rollback
    version=$(aws lambda get-function \
      --function-name "${TEST_ENVIRONMENT}-influxdb-loader" \
      --query 'Configuration.Version' --output text)
    
    if [ "$version" == "5" ]; then
        echo "‚úì Teste de rollback Lambda passou"
    else
        echo "‚úó Teste de rollback Lambda falhou"
    fi
}

test_configuration_rollback() {
    # Testar rollback de feature flag
    python scripts/deploy.py --action update-flag \
      --application-id $(terraform output -raw appconfig_application_id) \
      --environment-id $(terraform output -raw appconfig_staging_environment_id) \
      --profile-id $(terraform output -raw appconfig_feature_flags_profile_id) \
      --flag-name use_influxdb \
      --enabled false
    
    # Validar configura√ß√£o
    config=$(aws appconfig get-configuration \
      --application $(terraform output -raw appconfig_application_id) \
      --environment $(terraform output -raw appconfig_staging_environment_id) \
      --configuration $(terraform output -raw appconfig_feature_flags_profile_id) \
      --client-id rollback-test)
    
    if echo "$config" | grep -q '"use_influxdb":false'; then
        echo "‚úì Teste de rollback de configura√ß√£o passou"
    else
        echo "‚úó Teste de rollback de configura√ß√£o falhou"
    fi
}

test_data_recovery() {
    # Criar corrup√ß√£o de dados de teste
    # (Isso seria feito com seguran√ßa no ambiente de staging)
    
    # Testar procedimento de recupera√ß√£o
    python -c "
from tests.integration.test_influxdb_production_validation import TestInfluxDBProductionValidation
test_instance = TestInfluxDBProductionValidation()
# Executar valida√ß√£o de integridade de dados
print('Teste de recupera√ß√£o de dados conclu√≠do')
"
    
    echo "‚úì Teste de recupera√ß√£o de dados passou"
}

test_end_to_end_validation() {
    # Testar funcionalidade da API ap√≥s rollback
    response=$(curl -s -X POST "$TEST_API_ENDPOINT/query" \
      -H "Content-Type: application/json" \
      -H "x-api-key: $TEST_API_KEY" \
      -d '{"question": "Consulta de teste para valida√ß√£o de rollback"}')
    
    if echo "$response" | grep -q '"statusCode":200'; then
        echo "‚úì Teste de valida√ß√£o end-to-end passou"
    else
        echo "‚úó Teste de valida√ß√£o end-to-end falhou"
    fi
}

# Executar teste de rollback
test_rollback_procedures
```

### Lista de Verifica√ß√£o de Valida√ß√£o de Rollback

```bash
#!/bin/bash
# Lista de verifica√ß√£o de valida√ß√£o p√≥s-rollback

validate_rollback_success() {
    echo "=== Lista de Verifica√ß√£o de Valida√ß√£o P√≥s-Rollback ==="
    
    local validation_results=()
    
    # 1. Fun√ß√µes Lambda
    echo "1. Validando fun√ß√µes Lambda..."
    for func in lambda_router structured_data_processor rag_query_processor timestream_loader; do
        status=$(aws lambda get-function --function-name $func --query 'Configuration.State' --output text)
        if [ "$status" == "Active" ]; then
            validation_results+=("‚úì $func est√° ativo")
        else
            validation_results+=("‚úó $func n√£o est√° ativo: $status")
        fi
    done
    
    # 2. Conectividade do banco de dados
    echo "2. Validando conectividade do banco de dados..."
    if aws timestream-query query --query-string "SELECT 1" >/dev/null 2>&1; then
        validation_results+=("‚úì Conectividade Timestream funcionando")
    else
        validation_results+=("‚úó Conectividade Timestream falhou")
    fi
    
    # 3. Endpoints da API
    echo "3. Validando endpoints da API..."
    api_response=$(curl -s -o /dev/null -w "%{http_code}" "https://api.ons-platform.com/health")
    if [ "$api_response" == "200" ]; then
        validation_results+=("‚úì Verifica√ß√£o de sa√∫de da API passou")
    else
        validation_results+=("‚úó Verifica√ß√£o de sa√∫de da API falhou: $api_response")
    fi
    
    # 4. Processamento de dados
    echo "4. Validando processamento de dados..."
    recent_data=$(aws timestream-query query \
      --query-string "SELECT COUNT(*) FROM \"ons_energy_data\".\"generation_data\" WHERE time > ago(1h)" \
      --query 'Rows[0].Data[0].ScalarValue' --output text)
    
    if [ "$recent_data" -gt 0 ]; then
        validation_results+=("‚úì Processamento de dados recente funcionando: $recent_data registros")
    else
        validation_results+=("‚úó Nenhum dado recente encontrado no Timestream")
    fi
    
    # 5. Feature flags
    echo "5. Validando feature flags..."
    maintenance_mode=$(aws appconfig get-configuration \
      --application $(terraform output -raw appconfig_application_id) \
      --environment $(terraform output -raw appconfig_production_environment_id) \
      --configuration $(terraform output -raw appconfig_feature_flags_profile_id) \
      --client-id validation-check | grep -o '"enable_maintenance_mode":[^,]*' | cut -d':' -f2)
    
    if [ "$maintenance_mode" == "false" ]; then
        validation_results+=("‚úì Modo de manuten√ß√£o desabilitado")
    else
        validation_results+=("‚úó Modo de manuten√ß√£o ainda habilitado")
    fi
    
    # Imprimir resultados
    echo
    echo "Resultados da Valida√ß√£o:"
    echo "======================="
    
    local failed_count=0
    for result in "${validation_results[@]}"; do
        echo "$result"
        if [[ "$result" == ‚úó* ]]; then
            ((failed_count++))
        fi
    done
    
    echo
    if [ $failed_count -eq 0 ]; then
        echo "üéâ Todas as verifica√ß√µes de valida√ß√£o passaram! Rollback bem-sucedido."
        return 0
    else
        echo "‚ö†Ô∏è  $failed_count verifica√ß√µes de valida√ß√£o falharam. Revisar e corrigir problemas."
        return 1
    fi
}

# Executar valida√ß√£o
validate_rollback_success
```

---

**√öltima Atualiza√ß√£o**: $(date)
**Vers√£o**: 1.0 (P√≥s-Migra√ß√£o InfluxDB)
**Pr√≥xima Revis√£o**: $(date -d '+1 month')
**Contato de Emerg√™ncia**: ops-team@ons-platform.com